% Encoding: ISO-8859-1

@Article{Popescu2005,
  author  = {Popescu, A.C. and Farid, Hany},
  title   = {{Exposing digital forgeries by detecting traces of resampling}},
  journal = {IEEE Transactions on Signal Processing},
  year    = {2005},
  month   = {January},
  volume  = {53},
  pages   = {758-767},
  doi     = {10.1109/TSP.2004.839932},
}

@Article{Cozzolino2017,
  author  = {Cozzolino, Davide and Poggi, Giovanni},
  title   = {Autoencoder with recurrent neural networks for video forgery detection},
  journal = {Proceedings of the IS\&T Electronic Imaging},
  year    = {2017},
  pages   = {92-98},
  month   = {January},
  note    = {{Burlingame, CA}},
}

@InProceedings{Kirchner2008,
  author    = {Kirchner, Matthias},
  title     = {{Fast and reliable resampling detection by spectral analysis of fixed linear predictor residue}},
  booktitle = {ACM workshop on Multimedia and security (MM\&Sec)},
  year      = {2008},
}
{Bayar2016,
  author    = {Bayar, Belhassen and Stamm, Matthew C},
  title     = {A Deep Learning Approach To Universal Image Manipulation Detection Using A New Convolutional Layer},
  booktitle = {Proceedings of the ACM Workshop on Information Hiding and Multimedia Security},
  pages     = {5-10}
  year      = {2016},
  month     = {June},
  note      = {{Vigo, Spain}},
  doi       = {10.1145/2909827.2930786}s,
}

@InProceedings{Gaborini2015,
  author    = {Gaborini, Lorenzo and Bestagini, Paolo and Milani, Simone and Tagliasacchi, Marco and Tubaro, Stefano},
  title     = {Multi-clue image tampering localization},
  booktitle = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2015},
  doi       = {10.1109/WIFS.2014.7084315},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2015 - Gaborini et al. - Multi-clue image tampering localization.pdf:pdf},
  isbn      = {9781479988822},
  keywords  = {PRNU,PatchMatch,image forensics,near duplicates,tampering localization},
}

@InProceedings{Verdoliva2014,
  author    = {Verdoliva, Luisa and Cozzolino, Davide and Poggi, Giovanni},
  title     = {{A feature-based approach for image tampering detection and localization}},
  booktitle = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2014},
  doi       = {10.1109/WIFS.2014.7084319},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2014 - Verdoliva, Cozzolino, Poggi - A feature-based approach for image tampering detection and localization.pdf:pdf},
  isbn      = {978-1-4799-8882-2},
  url       = {http://ieeexplore.ieee.org/document/7084319/},
}

@Article{Cozzolino2014,
  author    = {D. Cozzolino and D. Gragnaniello and L. Verdoliva},
  title     = {Image forgery localization through the fusion of camera-based, feature-based and pixel-based techniques},
  journal   = {Proceedings of the IEEE International Conference on Image Processing},
  year      = {2014},
  month     = {October},
  note      = {{Paris, France}},
  pages     = {5302-5306},
  doi       = {10.1109/ICIP.2014.7026073},
  issn      = {1522-4880},
}

@article{Tuama2016,
  author    = {Tuama, Amel and Comby, Frederic and Chaumont, Marc},
  title     = {Source Camera Model Identification Using Features from Contaminated Sensor Noise},
  journal   = {Proceedings of the International Workshop on Digital-Forensics and Watermarking},
  pages     = {83-93},
  year      = {2016},
  month     = {October}, 
  note      = {{Tokyo, Japan}},
}

@Article{Gloe2010,
  author  = {Gloe, T. and B{\"o}hme, R.},
  title   = {The {Dresden} image database for benchmarking digital image forensics},
  journal = {Journal of Digital Forensic Practice},
  year    = {2010},
  volume  = {3},
  pages   = {150-159},
}


@InProceedings{Cozzolino2014a,
  author    = {Cozzolino, Davide and Gragnaniello, Diego and Verdoliva, Luisa},
  title     = {{Image forgery detection through residual-based local descriptors and block-matching}},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2014},
  doi       = {10.1109/ICIP.2014.7026072},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2014 - Cozzolino, Gragnaniello, Verdoliva - Image forgery detection through residual-based local descriptors and block-matching.pdf:pdf},
  isbn      = {978-1-4799-5751-4},
  url       = {http://ieeexplore.ieee.org/document/7026072/},
}

@Article{Bondi2017,
  author        = {Bondi, Luca and Baroffio, Luca and G\"{u}era, David and Bestagini, Paolo and Delp, Edward J. and Tubaro, Stefano},
  title         = {First Steps Toward Camera Model Identification With Convolutional Neural Networks},
  journal       = {IEEE Signal Processing Letters (SPL)},
  year          = {2017},
  month         = {March},
  volume        = {24},
  pages         = {259-263},
}

@Article{Gloe2009,
  author   = {Gloe, Thomas and Borowka, Karsten and Winkler, Antje},
  title    = {{Feature-based camera model identification works in Practice: Results of a comprehensive evaluation study}},
  journal  = {Lecture Notes in Computer Science},
  year     = {2009},
  volume   = {5806 LNCS},
  pages    = {262-276},
  abstract = {Feature-based camera model identification plays an important role in$\backslash$nthe toolbox for image source identification. It enables the forensic$\backslash$ninvestigator to discover the probable source model employed to acquire$\backslash$nan image under investigation. However, little is known about the$\backslash$nperformance on large sets of cameras that include multiple devices of$\backslash$nthe same model. Following the process of a forensic investigation, this$\backslash$npaper tackles important questions for the application of feature-based$\backslash$ncamera model identification in real world scenarios. More than 9,000$\backslash$nimages were acquired under controlled conditions using 44 digital$\backslash$ncameras of 12 different models. This forms the basis for an in-depth$\backslash$nanalysis of a) intra-camera model similarity, b) the number of required$\backslash$ndevices and images for training the identification method, and c) the$\backslash$ninfluence of camera settings. All experiments in this paper suggest:$\backslash$nfeature-based camera model identification works in practice and$\backslash$nprovides reliable results even if only one device for each camera model$\backslash$nunder investigation is available to the forensic investigator.},
  doi      = {10.1007/978-3-642-04431-1_19},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Gloe, Borowka, Winkler - Feature-based camera model identification works in Practice Results of a comprehensive evaluation study.pdf:pdf},
  isbn     = {3642044301},
  issn     = {03029743},
}

@article{Tuama2016a,
  author    = {Tuama, A. and Comby, F. and Chaumont, M.},
  title     = {Camera model identification based on machine learning approach with high order statistics features},
  journal   = {Proceedings of the IEEE European Signal Processing Conference},
  year      = {2016},
  month     = {August},
  note      = {{Budapest, Hungary}},
  pages     = {1183-1187},
  isbn      = {9780992862657},
  owner     = {bestagini},
  timestamp = {2016.09.15},
}

@Article{Chen2015,
  author  = {Chen, Jiansheng and Kang, Xiangui and Liu, Ye and Wang, Z Jane},
  title   = {{Median Filtering Forensics Based on Convolutional Neural Networks}},
  journal = {IEEE Signal Processing Letters},
  year    = {2015},
  volume  = {22},
  pages   = {1849-1853},
  number  = {11}, 
  month   = {November}
}

@Article{Swaminathan2008,
  author   = {A. Swaminathan and M. Wu and K. J. R. Liu},
  title    = {Digital image forensics via intrinsic fingerprints},
  journal  = {IEEE Transactions on Information Forensics and Security},
  year     = {2008},
  month    = {March},
  volume   = {3},
  number   = {1},
  pages    = {101-117},
}

@Article{Thai2017,
  author   = {Thai, Thanh Hai and Cogranne, Remi and Retraint, Florent and Doan, Thi-Ngoc-Canh},
  title    = {{JPEG Quantization Step Estimation and Its Applications to Digital Image Forensics}},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2017},
  volume   = {12},
  pages    = {123-133},
  abstract = {{\textcopyright} 2016 IEEE.The goal of the paper is to propose an accurate method for estimating quantization steps from an image that has been previously JPEG-compressed and stored in lossless format. The method is based on the combination of the quantization effect and the statistics of Discrete Cosine Transform (DCT) coefficient characterized by the statistical model that has been proposed in our previous works. The analysis of quantization effect is performed within a mathematical framework, which justifies the relation of local maxima of the number of integer quantized forward coefficients with the true quantization step. From the candidate set of the true quantization step given by the previous analysis, the statistical model of DCT coefficients is used to provide the optimal quantization step candidate. The proposed method can also be exploited to estimate the secondary quantization table in a double-JPEG compressed image stored in lossless format, and detect the presence of JPEG compression. Numerical experiments on large image databases with different image sizes and quality factors highlight the high accuracy of the proposed method.},
  doi      = {10.1109/TIFS.2016.2604208},
  issn     = {1556-6013},
  keywords = {Digital forensics,Discrete cosine transform,JPEG compression history,quantization step estimation,statistical image modeling},
  url      = {http://ieeexplore.ieee.org/document/7556411/},
}

@Article{Fridrich2009,
  author   = {Fridrich, Jessica},
  title    = {{Digital image forensics}},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2009},
  volume   = {26},
  number   = {2},
  pages    = {26--37},
  month    = {mar},
  issn     = {1053-5888},
  abstract = {The article explains how photo-response nonuniformity (PRNU) of imaging sensors can be used for a variety of important digital forensic tasks, such as device identification, device linking, recovery of processing history, and detection of digital forgeries. The PRNU is an intrinsic property of all digital imaging sensors due to slight variations among individual pixels in their ability to convert photons to electrons. Consequently, every sensor casts a weak noise-like pattern onto every image it takes. This pattern, which plays the role of a sensor fingerprint, is essentially an unintentional stochastic spread-spectrum watermark that survives processing, such as lossy compression or filtering. This tutorial explains how this fingerprint can be estimated from images taken by the camera and later detected in a given image to establish image origin and integrity. Various forensic tasks are formulated as a two-channel hypothesis testing problem approached using the generalized likelihood ratio test. The performance of the introduced forensic methods is briefly illustrated on examples to give the reader a sense of the performance.},
  doi      = {10.1109/MSP.2008.931078},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Fridrich - Digital image forensics.pdf:pdf},
  isbn     = {1053-5888 VO - 26},
  pmid     = {18642544},
  url      = {http://ieeexplore.ieee.org/document/4806203/},
}

@article{Cao2010,
  author        = {Cao, Gang and Zhao, Yao and Ni, Rongrong and Yu, Lifang and Tian, Huawei},
  title         = {Forensic detection of median filtering in digital images},
  journal       = {Proceedings of the IEEE International Conference on Multimedia and Expo},
  pages         = {89-94},
  year          = {2010},
  month         = {July},
  note          = {{Singapore}},
  doi           = {10.1109/ICME.2010.5583869},
}

@InProceedings{Kirchner2010,
  author    = {Kirchner, Matthias and Fridrich, Jessica},
  title     = {{On detection of median filtering in digital images}},
  booktitle = {SPIE Media Forensics and Security},
  year      = {2010},
  abstract  = {In digital image forensics, it is generally accepted that intentional manipulations of the image content are most critical and hence numerous forensic methods focus on the detection of such `malicious' post-processing. However, it is also beneficial to know as much as possible about the general processing history of an image, including content-preserving operations, since they can affect the reliability forensic methods in various ways. In this paper, we present a simple yet effective technique to detect median filtering in digital images--a widely used denoising and smoothing operator. As a great variety of forensic methods relies on some kind of a linearity assumption, a detection of non-linear median filtering is of particular interest. The effectiveness of our method is backed with experimental evidence on a large image database.},
}

@InProceedings{Qian2015,
  author    = {Qian, Yinlong and Dong, Jing and Wang, Wei and Tan, Tieniu},
  title     = {{Deep learning for steganalysis via convolutional neural networks}},
  booktitle = {SPIE Media Watermarking, Security, and Forensics},
  year      = {2015},
  abstract  = {Current work on steganalysis for digital images is focused on the construction of complex handcrafted features. This paper proposes a new paradigm for steganalysis to learn features automatically via deep learning models. We novelly propose a customized Convolutional Neural Network for steganalysis. The proposed model can capture the complex dependencies that are useful for steganalysis. Compared with existing schemes, this model can automatically learn feature representations with several convolutional layers. The feature extraction and classification steps are unified under a single architecture, which means the guidance of classification can be used during the feature extraction step. We demonstrate the effectiveness of the proposed model on three state-of-theart spatial domain steganographic algorithms - HUGO, WOW, and S-UNIWARD. Compared to the Spatial Rich Model (SRM), our model achieves comparable performance on BOSSbase and the realistic and large ImageNet database.},
  doi       = {10.1117/12.2083479},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2015 - Qian et al. - Deep learning for steganalysis via convolutional neural networks.pdf:pdf},
  isbn      = {9781628414998},
  issn      = {1996756X},
  keywords  = {Convolutional Neural Networks,Deep Learning,Feature Learning,Gaussian Nonlinearity,Steganalysis},
  url       = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2083479 http://www.scopus.com/inward/record.url?eid=2-s2.0-84932146885{\&}partnerID=tZOtx3y1},
}

@Article{Chiachia2014,
  author   = {Chiachia, Giovani and Falc??o, Alexandre X. and Pinto, Nicolas and Rocha, Anderson and Cox, David},
  title    = {{Learning person-specific representations from faces in the wild}},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2014},
  volume   = {9},
  pages    = {2089-2099},
  abstract = {Humans are natural face recognition experts, far out-performing current automated face recognition algorithms, especially in naturalistic, ???in the wild??? settings. However, a striking feature of human face recognition is that we are dramatically better at recognizing highly familiar faces, presumably because we can leverage large amounts of past experience with the appearance of an individual to aid future recognition. Meanwhile, the analogous situation in automated face recognition, where a large number of training examples of an individual are available, has been largely underexplored, in spite of the increasing relevance of this setting in the age of social media. Inspired by these observations, we propose to explicitly learn enhanced face representations on a per-individual basis, and we present two methods enabling this approach. By learning and operating within person-specific representations, we are able to significantly outperform the previous state-of-the-art on PubFig83, a challenging benchmark for familiar face recognition in the wild, using a novel method for learning representations in deep visual hierarchies. We suggest that such person-specific representations aid recognition by introducing an intermediate form of regularization to the problem.},
  doi      = {10.1109/TIFS.2014.2359543},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2014 - Chiachia et al. - Learning person-specific representations from faces in the wild.pdf:pdf},
  isbn     = {1556-6013 VO  - 9},
  issn     = {15566013},
  keywords = {Face recognition,biologically-inspired computer vision,deep learning,face information modeling,partial least squares,representation learning,support vector machines},
}

@Article{Tome2016,
  author        = {Tom{\`{e}}, Denis and Monti, Federico and Baroffio, Luca and Bondi, Luca and Tagliasacchi, Marco and Tubaro, Stefano},
  title         = {{Deep Convolutional Neural Networks for pedestrian detection}},
  journal       = {Signal Processing: Image Communication},
  year          = {2016},
  volume        = {47},
  pages         = {482-489},
  abstract      = {Pedestrian detection is a popular research topic due to its paramount importance for a number of applications, especially in the fields of automotive, surveillance and robotics. Despite the significant improvements, pedestrian detection is still an open challenge that calls for more and more accurate algorithms. In the last few years, deep learning and in particular convolutional neural networks emerged as the state of the art in terms of accuracy for a number of computer vision tasks such as image classification, object detection and segmentation, often outperforming the previous gold standards by a large margin. In this paper, we propose a pedestrian detection system based on deep learning, adapting a general-purpose convolutional network to the task at hand. By thoroughly analyzing and optimizing each step of the detection pipeline we propose an architecture that outperforms traditional methods, achieving a task accuracy close to that of state-of-the-art approaches, while requiring a low computational time. Finally, we tested the system on an NVIDIA Jetson TK1, a 192-core platform that is envisioned to be a forerunner computational brain of future self-driving cars.},
  archiveprefix = {arXiv},
  arxivid       = {1510.03608},
  doi           = {10.1016/j.image.2016.05.007},
  eprint        = {1510.03608},
  file          = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2016 - Tom{\`{e}} et al. - Deep Convolutional Neural Networks for pedestrian detection.pdf:pdf},
  issn          = {09235965},
  keywords      = {convolutional neural networks,deep learning,optimization,pedestrian detection},
  url           = {http://arxiv.org/abs/1510.03608 http://arxiv.org/abs/1510.03608{\%}5Cnhttp://www.arxiv.org/pdf/1510.03608.pdf http://linkinghub.elsevier.com/retrieve/pii/S0923596516300637},
}

@InProceedings{Taigman2014,
  author    = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  title     = {{DeepFace: Closing the Gap to Human-Level Performance in Face Verification}},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2014},
  doi       = {10.1109/CVPR.2014.220},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/Unknown - Taigman et al. - DeepFace Closing the Gap to Human-Level Performance in Face Verification.pdf:pdf},
  isbn      = {978-1-4799-5118-5},
  url       = {https://www.cs.toronto.edu/{~}ranzato/publications/taigman{\_}cvpr14.pdf http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909616},
}

@Article{Krizhevsky2012,
  author  = {Krizhevsky, Alex and Sulskever, IIya and Hinton, Geoffret E},
  title   = {{ImageNet Classification with Deep Convolutional Neural Networks}},
  journal = {Advances in Neural Information and Processing Systems (NIPS)},
  year    = {2012},
  pages   = {1-9},
  file    = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2012 - Krizhevsky, Sulskever, Hinton - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
}

@InProceedings{Szegedy2014,
  author        = {Szegedy, C and Liu, W and Jia, Y and Sermanet, P},
  title         = {{Going deeper with convolutions}},
  booktitle     = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year          = {2015},
  doi           = {10.1109/CVPR.2015.7298594},
  file          = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2014 - Szegedy et al. - Going deeper with convolutions.pdf:pdf},
  isbn          = {9781467369640},
  keywords      = {GoogLeNet},
  mendeley-tags = {GoogLeNet},
  url           = {/citations?view{\_}op=view{\_}citation{\&}continue=/scholar?hl=ja{\&}as{\_}sdt=0,5{\&}scilib=1{\&}citilm=1{\&}citation{\_}for{\_}view=KtmM-dAAAAAJ:JV2RwH3{\_}ST0C{\&}hl=ja{\&}oi=p},
}

@Article{Lin2013,
  author        = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  title         = {{Network In Network}},
  journal       = {arXiv preprint},
  year          = {2013},
  pages         = {10},
  abstract      = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
  archiveprefix = {arXiv},
  arxivid       = {1312.4400},
  eprint        = {1312.4400},
  file          = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2013 - Lin, Chen, Yan - Network In Network.pdf:pdf},
  url           = {http://arxiv.org/abs/1312.4400},
}

@Article{LeCun1998,
  author        = {LeCun, Yann and Bottou, L??on and Bengio, Yoshua and Haffner, Patrick},
  title         = {{Gradient-based learning applied to document recognition}},
  journal       = {Proceedings of the IEEE},
  year          = {1998},
  volume        = {86},
  pages         = {2278-2323},
  abstract      = {Multilayer neural networks trained with the back-propagation$\backslash$nalgorithm constitute the best example of a successful gradient based$\backslash$nlearning technique. Given an appropriate network architecture,$\backslash$ngradient-based learning algorithms can be used to synthesize a complex$\backslash$ndecision surface that can classify high-dimensional patterns, such as$\backslash$nhandwritten characters, with minimal preprocessing. This paper reviews$\backslash$nvarious methods applied to handwritten character recognition and$\backslash$ncompares them on a standard handwritten digit recognition task.$\backslash$nConvolutional neural networks, which are specifically designed to deal$\backslash$nwith the variability of 2D shapes, are shown to outperform all other$\backslash$ntechniques. Real-life document recognition systems are composed of$\backslash$nmultiple modules including field extraction, segmentation recognition,$\backslash$nand language modeling. A new learning paradigm, called graph transformer$\backslash$nnetworks (GTN), allows such multimodule systems to be trained globally$\backslash$nusing gradient-based methods so as to minimize an overall performance$\backslash$nmeasure. Two systems for online handwriting recognition are described.$\backslash$nExperiments demonstrate the advantage of global training, and the$\backslash$nflexibility of graph transformer networks. A graph transformer network$\backslash$nfor reading a bank cheque is also described. It uses convolutional$\backslash$nneural network character recognizers combined with global training$\backslash$ntechniques to provide record accuracy on business and personal cheques.$\backslash$nIt is deployed commercially and reads several million cheques per day$\backslash$n},
  annote        = {LeNet},
  archiveprefix = {arXiv},
  arxivid       = {1102.0183},
  doi           = {10.1109/5.726791},
  eprint        = {1102.0183},
  file          = {:Users/luca/OneDrive - Politecnico di Milano/Paper/1998 - LeCun et al. - Gradient-based learning applied to document recognition.pdf:pdf},
  isbn          = {0018-9219},
  issn          = {00189219},
  keywords      = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
  pmid          = {15823584},
}

@Article{Iandola2014,
  author        = {Iandola, Forrest and Moskewicz, Matt and Karayev, Sergey and Girshick, Ross and Darrell, Trevor and Keutzer, Kurt},
  title         = {{DenseNet: Implementing Efficient ConvNet Descriptor Pyramids}},
  year          = {2014},
  month         = {apr},
  abstract      = {Convolutional Neural Networks (CNNs) can provide accurate object classification. They can be extended to perform object detection by iterating over dense or selected proposed object regions. However, the runtime of such detectors scales as the total number and/or area of regions to examine per image, and training such detectors may be prohibitively slow. However, for some CNN classifier topologies, it is possible to share significant work among overlapping regions to be classified. This paper presents DenseNet, an open source system that computes dense, multiscale features from the convolutional layers of a CNN based object classifier. Future work will involve training efficient object detectors with DenseNet feature descriptors.},
  archiveprefix = {arXiv},
  arxivid       = {1404.1869},
  eprint        = {1404.1869},
  file          = {::},
  url           = {http://arxiv.org/abs/1404.1869},
}

@InProceedings{Lukas2005,
  author    = {Lukas, Jan and Fridrich, Jessica and Goljan, Miroslav},
  title     = {{Determining digital image origin using sensor imperfections}},
  booktitle = {Proceedings of the SPIE},
  year      = {2005},
  abstract  = {In this paper, we demonstrate that it is possible to use the sensors pattern noise for digital camera identification from images. The pattern noise is extracted from the images using a wavelet-based denoising filter. For each camera under investigation, we first determine its reference pattern, which serves as a unique identification fingerprint. This could be done using the process of flat-fielding, if we have the camera in possession, or by averaging the noise obtained from multiple images, which is the option taken in this paper. To identify the camera from a given image, we consider the reference pattern noise as a high-frequency spread spectrum watermark, whose presence in the image is established using a correlation detector. Using this approach, we were able to identify the correct camera out of 9 cameras without a single misclassification for several thousand images. Furthermore, it is possible to perform reliable identification even from images that underwent subsequent JPEG compression and/or resizing. These claims are supported by experiments on 9 different cameras including two cameras of exactly the same model.},
  annote    = {NULL},
  doi       = {10.1117/12.587105},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2005 - Luk{\'{a}}{\v{s}}, Fridrich, Goljan - Determining digital image origin using sensor imperfections.pdf:pdf},
  isbn      = {0-7803-9134-9},
  issn      = {0277786X},
  keywords  = {digital camera identification,fixed pattern noise,forensic,pattern noise,pixel non uniformity},
  url       = {http://link.aip.org/link/?PSI/5685/249/1{\&}Agg=doi{\%}5Cnhttp://ebooks.spiedigitallibrary.org/data/Conferences/SPIEP/26021/249{\_}1.pdf http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.587105},
}

@article{Lukas2006,
  author    = {Luk{\'a}{\v{s}}, Jan and Fridrich, Jessica and Goljan, Miroslav},
  title     = {Digital camera identification from sensor pattern noise},
  journal   = {IEEE Transactions on Information Forensics and Security},
  year      = {2006},
  month     = {June},
  volume    = {1},
  number    = {2},
  pages     = {205-214},
  owner     = {bestagini},
  publisher = {IEEE},
  timestamp = {2016.02.01},
}

@InProceedings{Goljan2008,
  author    = {Goljan, Miroslav and Fridrich, Jessica},
  title     = {{Camera identification from cropped and scaled images}},
  booktitle = {Proceedings of the SPIE Electronic Imaging},
  volume    = {6819},
  year      = {2008},
  month     = {January},
  note      = {{San Jose, CA}}, 
  doi       = {10.1117/12.766732},
}

@InProceedings{Goljan2009,
  author    = {Goljan, Miroslav and Fridrich, Jessica and Filler, Toma{\v{s}}},
  title     = {{Large scale test of sensor fingerprint camera identification}},
  booktitle = {SPIE Media Forensics and Security},
  year      = {2009},
  abstract  = {This paper presents a large scale test of camera identification from sensor fingerprints. To overcome the problem of acquiring a large number of cameras and taking the images, we utilized Flickr, an existing on-line image sharing site. In our experiment, we tested over one million images spanning 6896 individual cameras covering 150 models. The gathered data provides practical estimates of false acceptance and false rejection rates, giving us the opportunity to compare the experimental data with theoretical estimates. We also test images against a database of fingerprints, simulating thus the situation when a forensic analyst wants to find if a given image belongs to a database of already known cameras. The experimental results set a lower bound on the performance and reveal several interesting new facts about camera fingerprints and their impact on error analysis in practice. We believe that this study will be a valuable reference for forensic investigators in their effort to use this method in court.},
  annote    = {NULL},
  doi       = {10.1117/12.805701},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Goljan, Fridrich, Filler - Large scale test of sensor fingerprint camera identification.pdf:pdf},
  isbn      = {9780819475046},
  issn      = {0277786X},
  keywords  = {camera identification,digital forensics,photo response non uniformity,sensor fingerprint},
  url       = {http://link.aip.org/link/PSISDG/v7254/i1/p72540I/s1{\&}Agg=doi},
}

@InProceedings{Conotter2013,
  author    = {Conotter, V and Comesana, P. and Perez-Gonzalez, F.},
  title     = {{Forensic analysis of full-frame linearly filtered JPEG images}},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2013},
  abstract  = {The characteristic artifacts left in an image by JPEG compression are often exploited to gather information about the processing history of the content. However, linear image filtering, often applied as post-processing to the entire image (full-frame) for enhancement, may al-ter these forensically significant features, thus complicating the ap-plication of the related forensics techniques. In this paper, we study the combination of JPEG compression and full-frame linear filtering, analyzing their impact on the Discrete Cosine Transform (DCT) sta-tistical properties of the image. We derive an accurate mathematical framework that allows to fully characterize the probabilistic distri-butions of the DCT coefficients of the quantized and filtered image. We then exploit this knowledge to estimate the applied filter. Exper-imental results show the effectiveness of the proposed method.},
  doi       = {10.1109/ICIP.2013.6738930},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2013 - Conotter, Comesana, Perez-Gonzalez - Forensic analysis of full-frame linearly filtered JPEG images.pdf:pdf},
  isbn      = {978-1-4799-2341-0},
  keywords  = {Index Terms??? JPEG compression,linear filtering},
  url       = {http://ieeexplore.ieee.org/document/6738930/},
}

@Article{Pevny2008,
  author  = {Pevny, Tomas and Fridrich, Jessica},
  title   = {{Detection of Double-Compression in JPEG Images for Applications in Steganography}},
  journal = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year    = {2008},
  volume  = {3},
  pages   = {247-258},
  doi     = {10.1109/TIFS.2008.922456},
  file    = {:Users/luca/Desktop/Pevny, Fridrich - 2008 - Detection of Double-Compression in JPEG Images for Applications in Steganography.pdf:pdf},
  isbn    = {6077774464},
  issn    = {1556-6013},
  url     = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4512175 http://ieeexplore.ieee.org/document/4512175/},
}

@InProceedings{Hosang2015,
  author        = {Hosang, Jan and Omran, Mohamed and Benenson, Rodrigo and Schiele, Bernt},
  title         = {{Taking a deeper look at pedestrians}},
  booktitle     = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year          = {2015},
  abstract      = {In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection. Despite their recent diverse successes, convnets historically underperform compared to other pedestrian detectors. We deliberately omit explicitly modelling the problem into the network (e.g. parts or occlusion modelling) and show that we can reach competitive performance without bells and whistles. In a wide range of experiments we analyse small and big convnets, their architectural choices, parameters, and the influence of different training data, including pre-training on surrogate tasks. We present the best convnet detectors on the Caltech and KITTI dataset. On Caltech our convnets reach top perform-ance both for the Caltech1x and Caltech10x training setup. Using additional data at training time our strongest convnet model is competitive even to detectors that use additional data (optical flow) at test time.},
  archiveprefix = {arXiv},
  arxivid       = {1501.05790v1},
  doi           = {10.1109/CVPR.2015.7299034},
  eprint        = {1501.05790v1},
  file          = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2015 - Hosang, Benenson - Taking a Deeper Look at Pedestrians.pdf:pdf},
  isbn          = {978-1-4673-6964-0},
  issn          = {19375212},
  url           = {http://ieeexplore.ieee.org/document/7299034/},
}

@Article{Zampoglou2017,
  author    = {Zampoglou, Markos and Papadopoulos, Symeon and Kompatsiaris, Yiannis},
  title     = {{Large-scale evaluation of splicing localization algorithms for web images}},
  journal   = {Multimedia Tools and Applications},
  year      = {2017},
  volume    = {76},
  number    = {4},
  pages     = {4801--4834},
  month     = {feb},
  issn      = {1380-7501},
  doi       = {10.1007/s11042-016-3795-2},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2017 - Zampoglou, Papadopoulos, Kompatsiaris - Large-scale evaluation of splicing localization algorithms for web images.pdf:pdf},
  publisher = {Springer US},
  url       = {http://link.springer.com/10.1007/s11042-016-3795-2},
}

@Article{Lin2009,
  author   = {Lin, Zhouchen and He, Junfeng and Tang, Xiaoou and Tang, Chi Keung},
  title    = {{Fast, automatic and fine-grained tampered JPEG image detection via DCT coefficient analysis}},
  journal  = {Pattern Recognition},
  year     = {2009},
  volume   = {42},
  pages    = {2492-2501},
  abstract = {The quick advance in image/video editing techniques has enabled people to synthesize realistic images/videos conveniently. Some legal issues may arise when a tampered image cannot be distinguished from a real one by visual examination. In this paper, we focus on JPEG images and propose detecting tampered images by examining the double quantization effect hidden among the discrete cosine transform (DCT) coefficients. To our knowledge, our approach is the only one to date that can automatically locate the tampered region, while it has several additional advantages: fine-grained detection at the scale of 8 ?? 8 DCT blocks, insensitivity to different kinds of forgery methods (such as alpha matting and inpainting, in addition to simple image cut/paste), the ability to work without fully decompressing the JPEG images, and the fast speed. Experimental results on JPEG images are promising. ?? 2009 Elsevier Ltd. All rights reserved.},
  doi      = {10.1016/j.patcog.2009.03.019},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Lin et al. - Fast, automatic and fine-grained tampered JPEG image detection via DCT coefficient analysis.pdf:pdf},
  isbn     = {0031-3203},
  issn     = {00313203},
  keywords = {DCT coefficient,Double quantization,JPEG,Pattern analysis,Tampered image detection},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320309001198},
}

@Article{Li2009,
  author   = {Li, Weihai and Yuan, Yuan and Yu, Nenghai},
  title    = {{Passive detection of doctored JPEG image via block artifact grid extraction}},
  journal  = {Signal Processing},
  year     = {2009},
  volume   = {89},
  pages    = {1821-1829},
  abstract = {It has been noticed that the block artifact grids (BAG), caused by the blocking processing during JPEG compression, are usually mismatched when interpolating or concealing objects by copy???paste operations. In this paper, the BAGs are extracted blindly with a new extraction algorithm, and then abnormal BAGs can be detected with a marking procedure. Then the phenomenon of grid mismatch or grid blank can be taken as a trail of such forensics. Experimental results show that our method can mark these trails efficiently.},
  doi      = {10.1016/j.sigpro.2009.03.025},
  file     = {::},
  issn     = {01651684},
  url      = {http://www.sciencedirect.com/science/article/pii/S0165168409001315},
}

@Article{Farid2009,
  author   = {Farid, Hany},
  title    = {{Exposing Digital Forgeries From JPEG Ghosts}},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2009},
  volume   = {4},
  pages    = {154-160},
  abstract = {When creating a digital forgery, it is often necessary to combine several images, for example, when compositing one person's head onto another person's body. If these images were originally of different JPEG compression quality, then the digital composite may contain a trace of the original compression qualities. To this end, we describe a technique to detect whether the part of an image was initially compressed at a lower quality than the rest of the image. This approach is applicable to images of high and low quality as well as resolution.},
  doi      = {10.1109/TIFS.2008.2012215},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Farid - Exposing digital forgeries from JPEG ghosts.pdf:pdf},
  isbn     = {1595934936},
  issn     = {1556-6013},
  keywords = {Digital forensics,Digital tampering},
  url      = {http://ieeexplore.ieee.org/document/4773149/},
}

@Article{Krawetz2007,
  author   = {Krawetz, Neal},
  title    = {{A Picture's Worth...}},
  journal  = {Hacker Factor Solutions},
  year     = {2007},
  pages    = {1-31},
  abstract = {Kamera digital dan software video telah membuat lebih mudah dari sebelumnya untuk membuat gambar berkualitas tinggi dan film. Layanan seperti MySpace, Google Video, dan Flickr membuat sepele untuk mendistribusikan gambar, dan banyak yang diambil oleh media massa. Namun, ada masalah: bagaimana Anda bisa tahu jika video atau gambar yang nyata? Apakah komputer yang dihasilkan atau dimodifikasi? Dalam dunia di mana gambar yang lebih berpengaruh daripada kata-kata, mampu membedakan fakta dari fiksi dengan cara yang sistematis sangat penting. Makalah ini mencakup beberapa metode forensik umum dan tidak begitu umum untuk mengekstraksi informasi dari gambar digital. Makalah ini menjelaskan metode untuk membedakan gambar yang nyata dari yang dihasilkan komputer, dan mengidentifikasi bagaimana gambar telah dimanipulasi secara digital.},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2007 - Krawetz - A Picture's Worth.pdf:pdf},
}

@article{Stamm2013,
  author    = {Stamm, M. C. and {Min Wu} and Liu, K. J. R.},
  title     = {Information Forensics: An Overview of the First Decade},
  journal   = {IEEE Access},
  year      = {2013},
  volume    = {1},
  pages     = {167-200},
}

@article{Piva2013,
  author    = {Piva, A.},
  title     = {An Overview on Image Forensics},
  journal   = {ISRN Signal Processing},
  year      = {2013},
}

@InProceedings{Ye2007,
  author    = {Ye, Shuiming and Sun, Qibin and Chang, Ee-Chien},
  title     = {{Detecting Digital Image Forgeries by Measuring Inconsistencies of Blocking Artifact}},
  booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
  year      = {2007},
  volume    = {117543},
  abstract  = {Digital images can be forged easily with today's widely available image processing software. In this paper, we describe a passive approach to detect digital forgeries by checking inconsistencies of blocking artifact. Given a digital image, we find that the blocking artifacts introduced during JPEG compression could be used as a "natural authentication code". A blocking artifact measure is then proposed based on the estimated quantization table using the power spectrum of the DCT coefficient histogram. Experimental results also demonstrate the validity of the proposed approach.},
  doi       = {10.1109/ICME.2007.4284574},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2007 - Ye, Sun, Chang - Detecting Digital Image Forgeries by Measuring Inconsistencies of Blocking Artifact.pdf:pdf},
  isbn      = {1-4244-1016-9},
  url       = {http://ieeexplore.ieee.org/document/4284574/},
}

@InProceedings{Cozzolino2015,
  author    = {Cozzolino, Davide and Poggi, Giovanni and Verdoliva, Luisa},
  title     = {{Splicebuster: A new blind image splicing detector}},
  booktitle = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2015},
  abstract  = {We propose a new feature-based algorithm to detect image splicings without any prior information. Local features are computed from the co-occurrence of image residuals and used to extract synthetic feature parameters. Splicing and host images are assumed to be characterized by different parameters. These are learned by the image itself through the expectation-maximization algorithm together with the segmentation in genuine and spliced parts. A supervised version of the algorithm is also proposed. Preliminary results on a wide range of test images are very encouraging, showing that a limited-size, but meaningful, learning set may be sufficient for reliable splicing localization.},
  doi       = {10.1109/WIFS.2015.7368565},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2015 - Cozzolino, Poggi, Verdoliva - Splicebuster a new blind image splicing detector.pdf:pdf},
  isbn      = {9781467368025},
  keywords  = {Image forensics,blind algorithm,forgery detection and localization,local image descriptors},
}

@Article{Mahdian2009,
  author    = {Mahdian, Babak and Saic, Stanislav},
  title     = {{Using noise inconsistencies for blind image forensics}},
  journal   = {Image and Vision Computing},
  year      = {2009},
  volume    = {27},
  pages     = {1497-1503},
  abstract  = {A commonly used tool to conceal the traces of tampering is the addition of locally random noise to the altered image regions. The noise degradation is the main cause of failure of many active or passive image forgery detection methods. Typically, the amount of noise is uniform across the entire authentic image. Adding locally random noise may cause inconsistencies in the image's noise. Therefore, the detection of various noise levels in an image may signify tampering. In this paper, we propose a novel method capable of dividing an investigated image into various partitions with homogenous noise levels. In other words, we introduce a segmentation method detecting changes in noise level. We assume the additive white Gaussian noise. Several examples are shown to demonstrate the proposed method's output. An extensive quantitative measure of the efficiency of the noise estimation part as a function of different noise standard deviations, region sizes and various JPEG compression qualities is proposed as well. ?? 2009 Elsevier B.V. All rights reserved.},
  doi       = {10.1016/j.imavis.2009.02.001},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Mahdian, Saic - Using noise inconsistencies for blind image forensics.pdf:pdf},
  isbn      = {0262-8856},
  issn      = {02628856},
  keywords  = {Digital forgery,Image forensics,Image segmentation,Image tampering,Noise inconsistency},
  publisher = {Elsevier B.V.},
  url       = {http://dx.doi.org/10.1016/j.imavis.2009.02.001},
}

@Article{Ferrara2012,
  author   = {Ferrara, Pasquale and Bianchi, Tiziano and {De Rosa}, Alessia and Piva, Alessandro},
  title    = {{Image forgery localization via fine-grained analysis of CFA artifacts}},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2012},
  volume   = {7},
  pages    = {1566-1577},
  abstract = {In this paper, a forensic tool able to discriminate between original and forged regions in an image captured by a digital camera is presented. We make the assumption that the image is acquired using a Color Filter Array, and that tampering removes the artifacts due to the demosaicing algorithm. The proposed method is based on a new feature measuring the presence of demosaicing artifacts at a local level, and on a new statistical model allowing to derive the tampering probability of each 22 image block without requiring to know a priori the position of the forged region. Experimental results on different cameras equipped with different demosaicing algorithms demonstrate both the validity of the theoretical model and the effectiveness of our scheme.},
  doi      = {10.1109/TIFS.2012.2202227},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2012 - Ferrara et al. - Image forgery localization via fine-grained analysis of CFA artifacts.pdf:pdf},
  isbn     = {1556-6013 VO  - 7},
  issn     = {15566013},
  keywords = {CFA artifacts,digital camera demosaicking,forgery localization,image forensics,tampering probability map},
}

@InProceedings{Dirik2009,
  author    = {Dirik, Ahmet Emir and Memon, Nasir},
  title     = {{Image tamper detection based on demosaicing artifacts}},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2009},
  abstract  = {In this paper, we introduce tamper detection techniques based on artifacts created by Color Filter Array (CFA) processing in most digital cameras. The techniques are based on computing a single feature and a simple threshold based classifier. The efficacy of the approach was tested over thousands of authentic, tampered, and computer generated images. Experimental results demonstrate reasonably low error rates.},
  doi       = {10.1109/ICIP.2009.5414611},
  file      = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2009 - Dirik, Memon - Image tamper detection based on demosaicing artifacts.pdf:pdf},
  isbn      = {9781424456543},
  issn      = {15224880},
  keywords  = {CFA,Digital image forensics,Tamper detection},
}

@Article{Fontani2013,
  author   = {Fontani, Marco and Member, Student and Bianchi, Tiziano and Rosa, Alessia De},
  title    = {{A Framework for Decision Fusion in Image Forensics Based on Dempster ??? Shafer Theory of Evidence}},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2013},
  volume   = {8},
  pages    = {593-607},
  file     = {:Users/luca/OneDrive - Politecnico di Milano/Paper/2013 - Fontani et al. - A Framework for Decision Fusion in Image Forensics Based on Dempster ??? Shafer Theory of Evidence.pdf:pdf},
  keywords = {4,8,april 2013,e transactions on information,forensics and security,no,vol},
}

@Article{bianchi2012detection,
  author  = {Bianchi, Tiziano and Piva, Alessandro},
  title   = {Detection of nonaligned double {JPEG} compression based on integer periodicity maps},
  journal = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year    = {2012},
  volume  = {7},
  pages   = {842-848},
}

@Article{Iakovidou2017,
  author  = {Iakovidou, C. and Zampoglou, M. and Papadopoulos, S. and Kompatsiaris, Y.},
  title   = {Content-aware Detection of JPEG Grid Inconsistencies for Intuitive Image Forensics},
  journal = {(under review) IEEE Transactions on Information Forensics and Security (TIFS)},
  year    = {2017},
}

@article{Bondi2017a,
    author   = {Bondi, L. and G\"{u}era, D. and Baroffio, L. and Bestagini, P. and Delp, E. J. and Tubaro, S.}, 
    journal  = {Proceedings of the IS\&T International Symposium on Electronic Imaging}, 
    title    = {A Preliminary Study on Convolutional Neural Networks for Camera Model Identification}, 
    year     = {2017}, 
    note     = {{Burlingame, CA}}, 
    month    = {January}
}

@InCollection{Kirchner2015,
  author        = {Kirchner, M. and Gloe, T.},
  title         = {Forensic Camera Model Identification},
  booktitle     = {Handbook of Digital Forensics of Multimedia Data and Devices},
  publisher     = {John Wiley \& Sons, Ltd},
  year          = {2015},
  pages         = {329-374},
  address       = {{Chichester, UK}},
}

@InProceedings{Cozzolino2016,
  author    = {Cozzolino, Davide and Verdoliva, Luisa},
  title     = {{Single-image splicing localization through autoencoder-based anomaly detection}},
  booktitle = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2016},
  doi       = {10.1109/WIFS.2016.7823921},
  isbn      = {978-1-5090-1138-4},
}

@article{Rocha2011a,
  author     = {Rocha, Anderson and Scheirer, Walter and Boult, Terrance and Goldenstein, Siome},
  title      = {Vision of the Unseen: Current Trends and Challenges in Digital Image and Video Forensics},
  journal    = {ACM Computing Surveys},
  year       = {2011},
  volume     = {43},
  pages      = {1-42},
}

@article{Filler2008,
  author        = {Filler, T. and Fridrich, J. and Goljan, M.},
  title         = {Using Sensor Pattern Noise for Camera Model Identification},
  journal       = {Proccedings of the IEEE International Conference on Image Processing},
  year          = {2008},
  month         = {October},
  note          = {{San Diego, CA}},
  pages         = {1296-1299},
}


@Article{Bayram2005,
  author    = {Bayram, S. and Sencar, H. and Memon, N. and Avcibas, I.},
  title     = {Source camera identification based on {CFA} interpolation},
  journal   = {Proceedings of the IEEE International Conference on Image Processing},
  pages     = {69-72},
  year      = {2005},
  month     = {September},
  note      = {{Genova, Italy}},
}

@Article{Thai2014,
  author        = {Thai, T. H. and Cogranne, R. and Retraint, F.},
  title         = {Camera Model Identification Based on the Heteroscedastic Noise Model},
  journal       = {IEEE Transactions on Image Processing},
  year          = {2014},
  volume        = {23},
  pages         = {250-263},
}


@Article{Chen2007a,
  author    = {Chen, S.-H. and Hsu, C.-T.},
  title     = {Source Camera Identification Based on Camera Gain Histogram},
  journal   = {Proceedings of the IEEE International Conference on Image Processing},
  year      = {2007},
  month     = {September},
  note      = {{San Antonio, TX}},
  pages     = {429-432}, 
}

@Article{Choi2006,
  author    = {Choi, K.S. and Lam, E.Y. and Wong, K.K.Y.},
  title     = {Automatic source camera identification using the intrinsic lens radial distortion},
  journal   = {Optics Express},
  year      = {2006},
  month     = {November},
  volume    = {14},
  number    = {24}, 
  pages     = {11551-11565},
}


@InCollection{Marra2015,
  pages     = {11--18},
  title     = {Evaluation of Residual-Based Local Features for Camera Model Identification},
  publisher = {Springer International Publishing},
  address   = {{Cham, Switzerland}}, 
  year      = {2015},
  author    = {Marra, F. and Poggi, G. and Sansone, C. and Verdoliva, L.},
  editor    = {Murino, Vittorio and Puppo, Enrico and Sona, Diego and Cristani, Marco and Sansone, Carlo},
  booktitle = {New Trends in Image Analysis and Processing -- ICIAP 2015 Workshops},
}


@article{Zhao2016,
  author    = {X. Zhao and M. C. Stamm},
  title     = {Computationally efficient demosaicing filter estimation for forensic camera model identification},
  journal   = {Proceedings of the IEEE International Conference on Image Processing},
  year      = {2016},
  pages     = {151-155}, 
  month     = {September},
  note      = {{Phoenix, AZ}}
}

@Article{Chen2015a,
  author  = {Chen, C. and Stamm, M. C.},
  title   = {Camera model identification framework using an ensemble of demosaicing features},
  journal = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year    = {2015},
}

@Article{Bondi2017b,
  author  = {Bondi, L. and Lameri, S. and G\"{u}era, D. and Bestagini, P. and Delp, E. J. and Tubaro, S.},
  title   = {Tampering Detection and Localization through Clustering of Camera-Based CNN Features},
  journal = {IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year    = {2017},
}

@book{Goodfellow2016,
  title     = {Deep Learning},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher = {MIT Press},
  address   = {Cambridge, MA},
  year      = {2016}
}

@article{LeCun2015,
  title     = {Deep learning},
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal   = {Nature},
  volume    = {521},
  number    = {7553},
  pages     = {436-444},
  year      = {2015},
  month     = {May},
}

@article{Buccoli2014,
  author    = {Buccoli, M. and Bestagini, P. and Zanoni, M. and Sarti, A. and Tubaro, S.},
  title     = {Unsupervised feature learning for bootleg detection using deep learning architectures},
  journal   = {Proceedings of the IEEE International Workshop on Information Forensics and Security},
  year      = {2014},
  month     = {December},
  note      = {{Atlanta, GA}},
  pages     = {131-136},
}

@Article{Bayar2016,
  author  = {Bayar, B. and Stamm, M. C.},
  title   = {A Deep Learning Approach to Universal Image Manipulation Detection Using a New Convolutional Layer},
  journal = {ACM Workshop on Information Hiding and Multimedia Security (IHMMSEC)},
  year    = {2016},
}

@article{Xu2016,
  author  = {G. Xu and H. Z. Wu and Y. Q. Shi},
  title   = {Structural Design of Convolutional Neural Networks for Steganalysis},
  journal = {IEEE Signal Processing Letters},
  year    = {2016},
  month   = {May}, 
  volume  = {23},
  number  = {5}, 
  pages   = {708-712},
  issn    = {1070-9908},
}

@article{Xu2017, 
    author={G. Xu and H. Z. Wu and Y. Q. Shi}, 
    journal={IEEE Signal Processing Letters}, 
    title={Structural Design of Convolutional Neural Networks for Steganalysis}, 
    year={2016}, 
    volume={23}, 
    number={5}, 
    pages={708-712}, 
    month={May},
}

@article{Chen2017,
    author = {Chen, Mo and Sedighi, Vahid and Boroumand, Mehdi and Fridrich, Jessica},
    title = {JPEG-Phase-Aware Convolutional Neural Network for Steganalysis of JPEG Images},
    journal = {Proceedings of the ACM Workshop on Information Hiding and Multimedia Security},
    year = {2017},
    month = {June},
    note = {{Philadelphia, PA}},
    pages = {75-84},
} 

@Article{Kingma2014,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  journal   = {Proceedings of the International Conference on Learning Representations},
  volume    = {arXiv},
  number    = {1412.6980},
  year      = {2015},
  month     = {May},
  note      = {{San Diego, CA}}
}

@Article{Smith2015,
  author   = {L. N. Smith}, 
  journal  = {Proceedings of the IEEE Winter Conference on Applications of Computer Vision}, 
  title    = {Cyclical Learning Rates for Training Neural Networks}, 
  year     = {2017}, 
  pages    = {464-472}, 
  month    = {March},
  note     = {{Santa Rosa, CA}}
}

@InProceedings{Bestagini2012,
  author    = {Bestagini, P. and Allam, A. and Milani, S. and Tagliasacchi, M. and Tubaro, S.},
  title     = {Video codec identification},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2012},
  doi       = {10.1109/ICASSP.2012.6288363},
  issn      = {1520-6149},
  keywords  = {coding based footprint;coding steps;lossy coding;multimedia forensic;reconstructed sequence reencoding;video codec identification;video content;video stream;image reconstruction;image sequences;video codecs;video coding;video streaming;},
  owner     = {bestagini},
  timestamp = {2012.10.05},
}

@InProceedings{Bestagini2013,
  author    = {Bestagini, P. and Battaglia, S. and Milani, S. and Tagliasacchi, M. and Tubaro, S.},
  title     = {Detection of temporal interpolation in video sequences},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2013},
  owner     = {bestagini},
  timestamp = {2012.10.05},
}

@InProceedings{Bestagini2013b,
  author    = {Bestagini, P. and Milani, S. and Tagliasacchi, M. and Tubaro, S.},
  title     = {Local tampering detection in video sequences},
  booktitle = {IEEE International Workshop on Multimedia Signal Processing (MMSP)},
  year      = {2013},
  owner     = {bestagini},
  timestamp = {2013.08.28},
}

@Article{Bestagini2016,
  author    = {Bestagini, P. and Milani, S. and Tagliasacchi, M. and Tubaro, S.},
  title     = {Codec and {GOP} Identification in Double Compressed Videos},
  journal   = {IEEE Transactions on Image Processing (TIP)},
  year      = {2016},
  volume    = {25},
  pages     = {2298-2310},
  issn      = {1057-7149},
  keywords  = {data compression;image sequences;video coding;DIRAC;GOP identification;H.264-AVC;MPEG-2;MPEG-4;YouTube;coding-based footprint;digital compressed format;double compressed video codec;group of picture;video forensics;video quality assessment;video sequence;Codecs;Encoding;Image coding;Standards;Transform coding;Video sequences;Videos;GOP identification;Video forensics;coding-based footprints;video codec},
  owner     = {bestagini},
  timestamp = {2016.07.28},
}

@Article{Milani2012a,
  author    = {Milani, S. and Fontani, M. and Bestagini, P. and Barni, M. and Piva, A. and Tagliasacchi, M. and Tubaro, S.},
  title     = {An overview on video forensics},
  journal   = {APSIPA Transactions on Signal and Information Processing},
  year      = {2012},
  volume    = {1},
  pages     = {e2},
}

@InProceedings{DAmiano2015,
  author    = {D'Amiano, L. and Cozzolino, D. and Poggi, G. and Verdoliva, L.},
  title     = {Video forgery detection and localization based on {3D} patchmatch},
  booktitle = {IEEE International Conference on Multimedia Expo Workshops (ICMEW)},
  year      = {2015},
  keywords  = {image matching;search problems;video signal processing;3D patchmatch;ad hoc fast post-processing;approximate nearest neighbor search;copy-move video forgeries;dense-field matching;false alarm removal;noise-resilient rotation-invariant features;video forgery detection;video forgery localization;Feature extraction;Forensics;Forgery;Noise;Robustness;Security;Signal processing algorithms;Digital image forensics;PatchMatch;copy-move forgery detection},
  owner     = {bestagini},
  timestamp = {2016.07.28},
}

@Article{Stamm2012,
  author    = {Stamm, {M.C.} and Lin, {W.S.} and Liu, {K.J.R.}},
  title     = {Temporal Forensics and Anti-Forensics for Motion Compensated Video},
  journal   = {{IEEE} Transactions on Information Forensics and Security (TIFS)},
  year      = {2012},
  volume    = {7},
  pages     = {1315 --1329},
  abstract  = {Due to the ease with which digital information can be altered, many digital forensic techniques have been developed to authenticate multimedia content. Similarly, a number of anti-forensic operations have recently been designed to make digital forgeries undetectable by forensic techniques. However, like the digital manipulations they are designed to hide, many anti-forensic operations leave behind their own forensically detectable traces. As a result, a digital forger must balance the trade-off between completely erasing evidence of their forgery and introducing new evidence of anti-forensic manipulation. Because a forensic investigator is typically bound by a constraint on their probability of false alarm (P\_fa), they must also balance a trade-off between the accuracy with which they detect forgeries and the accuracy with which they detect the use of anti-forensics. In this paper, we analyze the interaction between a forger and a forensic investigator by examining the problem of authenticating digital videos. Specifically, we study the problem of adding or deleting a sequence of frames from a digital video. We begin by developing a theoretical model of the forensically detectable fingerprints that frame deletion or addition leaves behind, then use this model to improve upon the video frame deletion or addition detection technique proposed by Wang and Farid. Next, we propose an anti-forensic technique designed to fool video forensic techniques and develop a method for detecting the use of anti-forensics. We introduce a new set of techniques for evaluating the performance of anti-forensic operations and develop a game theoretic framework for analyzing the interplay between a forensic investigator and a forger. We use these new techniques to evaluate the performance of each of our proposed forensic and anti-forensic techniques, and identify the optimal actions of both the forger and forensic investigator.},
  doi       = {10.1109/TIFS.2012.2205568},
  file      = {IEEE Xplore Full Text PDF:/Users/bestagini/Documents/Zotero/storage/SE5DZ8VU/Stamm et al. - 2012 - Temporal Forensics and Anti-Forensics for Motion C.pdf:application/pdf},
  issn      = {1556-6013},
  keywords  = {addition detection technique, Anti-Forensics, antiforensic manipulation, computer forensics, digital forensic technique, digital forensics, digital forgeries, digital manipulation, digital video authentication, false alarm probability, forgery, frame deletion, game theoretic framework, game theory, Heuristic algorithms, Mathematical model, message authentication, motion compensated video, motion compensation, Multimedia communication, multimedia content, temporal forensics, video coding, Video compression, video forensic technique, video frame deletion},
  owner     = {bestagini},
  timestamp = {2013.04.02},
}

@Article{Bian2014,
  author   = {S. Bian and W. Luo and J. Huang},
  title    = {Exposing Fake Bit Rate Videos and Estimating Original Bit Rates},
  journal  = {IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)},
  year     = {2014},
  volume   = {24},
  pages    = {2144-2154},
  doi      = {10.1109/TCSVT.2014.2334031},
  issn     = {1051-8215},
  keywords = {discrete cosine transforms;frequency-domain analysis;image resolution;image sequences;statistical analysis;vector quantisation;video coding;16-D feature vector;DCT frequency domain;digital video forensic;digital video quality;fake bit rate MPEG-2 video expose;first-digit law;original bit rate estimation;query video;requantization artifact;sequential bit rate down-converted version;spatial domain;statistical artifact analysis;video compression;video resolution;video sequence;Feature extraction;Forensics;Quality assessment;Transform coding;Video recording;Videos;Visualization;Digital video forensics;video bit rate estimation;video quality forgery},
}

@Article{Hajj-Ahmad2017,
  author   = {A. Hajj-Ahmad and S. Baudry and B. Chupeau and G. Do?rr and M. Wu},
  title    = {Flicker Forensics for Camcorder Piracy},
  journal  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  year     = {2017},
  volume   = {12},
  pages    = {89-100},
  doi      = {10.1109/TIFS.2016.2603603},
  issn     = {1556-6013},
  keywords = {digital forensics;video recording;LCD screen;backlight frequency;backlight technology;camcorder piracy;copyrighted content;flicker forensics;flicker signal;liquid-crystal-display screen;luminance flicker;Forensics;Indexes;Liquid crystal displays;Liquid crystals;Motion pictures;Videos;LCD screen;Movie piracy;aliasing;backlight;camcorder;rolling shutter},
}

@InProceedings{D.DAvino2017,
  author    = {D'Avino, D. and Cozzolino, D. and Poggi, G. and Verdoliva, L.},
  title     = {Autoencoder with Recurrent Neural Networks for video forgery detection},
  booktitle = {IS\&T Electronic Imaging (EI)},
  year      = {2017},
  owner     = {bestagini},
  timestamp = {2016.07.26},
}

@InProceedings{DangNguyen2014,
  author    = {D. T. Dang-Nguyen and V. Conotter and G. Boato and F. G. B. De Natale},
  title     = {Video forensics based on expression dynamics},
  booktitle = {2014 IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2014},
  pages     = {161-166},
  month     = {Dec},
  doi       = {10.1109/WIFS.2014.7084321},
  issn      = {2157-4766},
  keywords  = {emotion recognition;image forensics;image sequences;computer generated video;digital graphics tools;expression dynamics;facial dynamics;facial expressions;mechanical properties;natural muscle movements;real humans;spatiotemporal appearance;temporal information;video forensics;video sequence;Accuracy;Databases;Face;Feature extraction;Forensics;Three-dimensional displays;Video sequences},
}

@InProceedings{Bayram2008,
  author    = {Bayram, Sevinc and Sencar, Husrev Taha and Memon, Nasir},
  title     = {Video Copy Detection Based on Source Device Characteristics: A Complementary Approach to Content-based Methods},
  booktitle = {ACM International Conference on Multimedia Information Retrieval},
  year      = {2008},
  acmid     = {1460167},
  isbn      = {978-1-60558-312-9},
  location  = {Vancouver, British Columbia, Canada},
  numpages  = {8},
}

@InProceedings{Chen2007,
  author    = {Chen, M. and Fridrich, J. and Goljan, M. and Lukas, J.},
  title     = {Source Digital Camcorder Identification Using Sensor Photo-Response NonUniformity},
  booktitle = {SPIE Electronic Imaging (EI)},
  year      = {2007},
}

@InProceedings{VisentiniScarzanella2012,
  author    = {M. Visentini-Scarzanella and P. L. Dragotti},
  title     = {Video jitter analysis for automatic bootleg detection},
  booktitle = {IEEE International Workshop on Multimedia Signal Processing (MMSP)},
  year      = {2012},
  doi       = {10.1109/MMSP.2012.6343423},
}

@InProceedings{Hsu2008,
  author    = {Hsu, Chih-Chung and Hung, Tzu-Yi and Lin, Chia-Wen and Hsu, Chiou-Ting},
  title     = {Video forgery detection using correlation of noise residue},
  booktitle = {IEEE Workshop on Multimedia Signal Processing (MMSP)},
  year      = {2008},
  abstract  = {We propose a new approach for locating forged regions in a video using correlation of noise residue. In our method, block-level correlation values of noise residual are extracted as a feature for classification. We model the distribution of correlation of temporal noise residue in a forged video as a Gaussian mixture model ({GMM).} We propose a two-step scheme to estimate the model parameters. Consequently, a Bayesian classifier is used to find the optimal threshold value based on the estimated parameters. Two video inpainting schemes are used to simulate two different types of forgery processes for performance evaluation. Simulation results show that our method achieves promising accuracy in video forgery detection.},
  doi       = {10.1109/MMSP.2008.4665069},
  file      = {IEEE Xplore Full Text PDF:/Users/bestagini/Documents/Zotero/storage/HC4G5S2V/Hsu et al. - 2008 - Video forgery detection using correlation of noise.pdf:PDF},
  keywords  = {Bayes methods, Bayesian classifier, Biosensors, block-level correlation values, Digital cameras, Feature extraction, Fingerprint recognition, Forensics, forgery, forgery processes, Gaussian mixture model, Gaussian processes, image classification, image coding, Image sensors, noise residue correlation, optimal threshold value, Parameter estimation, Pipelines, signal detection, video forgery detection, video inpainting schemes, video signal processing, Watermarking},
  owner     = {bestagini},
  timestamp = {2013.04.02},
}

@Article{Conotter2012,
  author    = {Conotter, V. and {O'Brien}, {J.F.} and Farid, H.},
  title     = {Exposing Digital Forgeries in Ballistic Motion},
  journal   = {{IEEE} Transactions on Information Forensics and Security (TIFS)},
  year      = {2012},
  volume    = {7},
  pages     = {283--296},
  abstract  = {We describe a geometric technique to detect physically implausible trajectories of objects in video sequences. This technique explicitly models the three-dimensional ballistic motion of objects in free-flight and the two-dimensional projection of the trajectory into the image plane of a static or moving camera. Deviations from this model provide evidence of manipulation. The technique assumes that the object's trajectory is substantially influenced only by gravity, that the image of the object's center of mass can be determined from the images, and requires that any camera motion can be estimated from background elements. The computational requirements of the algorithm are modest, and any detected inconsistencies can be illustrated in an intuitive, geometric fashion. We demonstrate the efficacy of this analysis on videos of our own creation and on videos obtained from video-sharing websites.},
  doi       = {10.1109/TIFS.2011.2165843},
  file      = {IEEE Xplore Full Text PDF:/Users/bestagini/Documents/Zotero/storage/VIVBM4HG/Conotter et al. - 2012 - Exposing Digital Forgeries in Ballistic Motion.pdf:application/pdf},
  issn      = {1556-6013},
  keywords  = {background elements, Cameras, computer forensics, digital forensics, digital forgeries, Equations, Estimation, Forensics, fraud, free-flight projection, image plane, image sequences, motion estimation, moving camera, object detection, physically implausible object trajectory detection, Projectiles, Security, static camera, three-dimensional ballistic motion, Trajectory, two-dimensional trajectory projection, Video forensics, video sequences, video signal processing, video-sharing Web sites, Web sites},
  owner     = {bestagini},
  timestamp = {2013.04.02},
}

@InProceedings{Milani2012,
  author    = {Milani, S. and Bestagini, P. and Tagliasacchi, M. and Tubaro, S.},
  title     = {Multiple compression detection for video sequences},
  booktitle = {IEEE International Workshop on Multimedia Signal Processing (MMSP)},
  year      = {2012},
  doi       = {10.1109/MMSP.2012.6343425},
}

@InProceedings{Chuang2011,
  author    = {Chuang, Wei-Hong and Su, Hui and Wu, Min},
  title     = {Exploring compression effects for improved source camera identification using strongly compressed video},
  booktitle = {{IEEE} International Conference on Image Processing ({ICIP)}},
  year      = {2011},
  abstract  = {This paper presents a study of the video compression effect on source camera identification based on the Photo-Response Non-Uniformity ({PRNU).} Specifically, the reliability of different types of frames in a compressed video is first investigated, which shows quantitatively that I-frames are more reliable than P-frames for {PRNU} estimation. Motivated by this observation, a new mechanism for estimating the reference {PRNU} and two mechanisms for estimating the test-video {PRNU} are proposed to achieve higher accuracy with fewer frames used. Experiments are performed to validate the effectiveness of the proposed mechanisms.},
  doi       = {10.1109/ICIP.2011.6115855},
  file      = {IEEE Xplore Full Text PDF:/Users/bestagini/Documents/Zotero/storage/KG8UF38X/Chuang et al. - 2011 - Exploring compression effects for improved source .pdf:application/pdf},
  keywords  = {Cameras, computer forensics, Correlation, data compression, Digital video forensics, Estimation, Forensics, image coding, low-bit-rate video compression, Noise, photo-response non-uniformity, photoresponse non-uniformity, {PRNU} estimation, Reliability, source camera identification, video cameras, video coding, Video compression},
  owner     = {bestagini},
  timestamp = {2013.04.02},
}

@Article{Tuama2016b,
  author  = {A. Tuama and F. Comby and M. Chaumont},
  title   = {Camera model identification with the use of deep convolutional neural networks},
  journal = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year    = {2016},
}

@Article{Chen2015b,
  author  = {Chen, Jiansheng and Kang, Xiangui and Liu, Ye and Wang, Z Jane},
  title   = {{Median Filtering Forensics Based on Convolutional Neural Networks}},
  journal = {IEEE Signal Processing Letters},
  year    = {2015},
  volume  = {22},
  pages   = {1849-1853},
  number  = {11},
  month   = {November},
}

@Article{Mihcak1999,
  author    = {Mihcak, M. K. and Kozintsev, I. and Ramchandran, K. and Moulin, P.},
  title     = {Low-complexity image denoising based on statistical modeling of wavelet coefficients},
  journal   = {IEEE Signal Processing Letters (SPL)},
  year      = {1999},
  volume    = {6},
  pages     = {300-303},
  doi       = {10.1109/97.803428},
  issn      = {1070-9908},
  keywords  = {AWGN;image restoration;least mean squares methods;parameter estimation;probability;statistical analysis;wavelet transforms;AWGN;additive white Gaussian noise;approximate maximum a posteriori probability rule;approximate minimum mean squared error estimation;estimation-quantization coder;high local correlation;low-complexity image denoising;marginal prior distribution;spatially adaptive statistical model;statistical modeling;wavelet coefficients;wavelet image coefficients;wavelet image compression algorithm;zero-mean Gaussian random variables;AWGN;Additive white noise;Gaussian noise;Histograms;Image coding;Image denoising;Image processing;Noise reduction;Random variables;Wavelet coefficients},
  owner     = {bestagini},
  timestamp = {2014.05.23},
}

@InProceedings{Milani2014a,
  Title                    = {Demosaicing strategy identification via eigenalgorithms},
  Author                   = {Milani, S. and Bestagini, P. and Tagliasacchi, M. and Tubaro, S.},
  Booktitle                = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  Year                     = {2014},

  ISSN                     = {1520-6149},
  Owner                    = {bestagini},
  Timestamp                = {2015.05.20}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825-2830},
 year={2011}
}

@InProceedings{Agarwal2017,
  author    = {Agarwal, S. and Farid, H.},
  title     = {Photo forensics from {JPEG} dimples},
  booktitle = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  year      = {2017},
}

@Article{Fan2003,
  author   = {Zhigang Fan and R. L. de Queiroz},
  title    = {Identification of bitmap compression history: {JPEG} detection and quantizer estimation},
  journal  = {IEEE Transactions on Image Processing (TIP)},
  year     = {2003},
  volume   = {12},
  pages    = {230-235},
  keywords = {code standards;data compression;image coding;maximum likelihood estimation;quantisation (signal);telecommunication standards;JPEG detection;JPEG quantization;bitmap compression history identification;compression parameters estimation;compression signature detection;estimated quantizer step size;image compression;image processing;image quality;maximum likelihood estimation;quantization table;quantizer estimation;quantizer estimation method;raster bitmap format;Discrete cosine transforms;History;Image coding;Image processing;Image quality;Maximum likelihood estimation;Parameter estimation;Quantization;Rendering (computer graphics);Transform coding},
}

@InProceedings{Schaefer2004,
  author    = {Schaefer, G. and Stich, M.},
  title     = {{UCID} - An Uncompressed Colour Image Database},
  booktitle = {SPIE Storage and Retrieval Methods and Applications for Multimedia},
  year      = {2004},
}

@Misc{nimble,
  author       = {NIST},
  title        = {{Nimble Challenge 2017 Dataset (NC2017)} for image manipulation detection},
  howpublished = {Available at: https://www.nist.gov/itl/iad/mig/media-forensics-challenge},
}

@Article{Milani2014,
  Title                    = {Discriminating Multiple {JPEG} Compressions Using First Digit Features},
  Author                   = {Milani, S. and Tagliasacchi, M. and Tubaro, S.},
  Journal                  = {APSIPA Transactions on Signal and Information Processing},
  Pages                    = {1-11},
  Volume                   = {3},
  Year                     = {2014},
}

@InProceedings{pasquini2014multiple,
  Title                    = {Multiple {JPEG} compression detection by means of {Benford-Fourier} coefficients},
  Author                   = {Pasquini, Cecilia and Boato, Giulia and P{\'e}rez-Gonz{\'a}lez, Fernando},
  Booktitle                = {IEEE International Workshop on Information Forensics and Security (WIFS)},
  Year                     = {2014}
}

@article{bonettini2017,
	title = "Aligned and non-aligned double {JPEG} detection using convolutional neural networks",
	journal = "Journal of Visual Communication and Image Representation (JVCI)",
	volume = "49",
	pages = "153-163",
	year = "2017",
	author = "M. Barni and L. Bondi and N. Bonettini and P. Bestagini and A. Costanzo and M. Maggini and B. Tondi and S. Tubaro",
}

@InProceedings{Bianchi2011,
  Title                    = {{Detection of non-aligned double {JPEG} compression with estimation of primary compression parameters}},
  Author                   = {Bianchi, Tiziano and Piva, Alessandro},
  Booktitle                = {IEEE International Conference on Image Processing (ICIP)},
  Year                     = {2011},
  Keywords                 = {data compression;discrete cosine transforms;featur},
  Owner                    = {nico},
  Timestamp                = {2017.06.23}
}

@Article{wang2016,
  Title                    = {Double {JPEG} compression forensics based on a convolutional neural network},
  Author                   = {Wang, Qing and Zhang, Rong},
  Journal                  = {EURASIP Journal on Information Security},
  Pages                    = {1-23},
  Volume                   = {2016},
  Year                     = {2016},
  Publisher                = {Springer}
}

@Article{Thai2016,
  Title                    = {{JPEG} Quantization Step Estimation and Its Applications to Digital Image Forensics},
  Author                   = {Thai, T. and Cogranne, R. and Retraint, F. and Doan, T.},
  Journal                  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  Pages                    = {123-133},
  Volume                   = {12},
  Year                     = {2017},
  Abstract                 = {{\textcopyright} 2016 IEEE.The goal of the paper is to propose an accurate method for estimating quantization steps from an image that has been previously JPEG-compressed and stored in lossless format. The method is based on the combination of the quantization effect and the statistics of Discrete Cosine Transform (DCT) coefficient characterized by the statistical model that has been proposed in our previous works. The analysis of quantization effect is performed within a mathematical framework, which justifies the relation of local maxima of the number of integer quantized forward coefficients with the true quantization step. From the candidate set of the true quantization step given by the previous analysis, the statistical model of DCT coefficients is used to provide the optimal quantization step candidate. The proposed method can also be exploited to estimate the secondary quantization table in a double-JPEG compressed image stored in lossless format, and detect the presence of JPEG compression. Numerical experiments on large image databases with different image sizes and quality factors highlight the high accuracy of the proposed method.},
}

@Article{SVMhistograms,
  Title                    = {Detection of Double-Compression in {JPEG} Images for Applications in Steganography},
  Author                   = {T. Pevny and J. Fridrich},
  Journal                  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  Pages                    = {247-258},
  Volume                   = {3},
  Year                     = {2008},

  __markedentry            = {[bestagini:1]},
  Doi                      = {10.1109/TIFS.2008.922456},
  Keywords                 = {Q-factor;cryptography;data compression;data encapsulation;discrete cosine transforms;image coding;maximum likelihood estimation;signal detection;support vector machines;JPEG compression;JPEG images;blind steganalysis methods;feature vectors;histograms;low-frequency discrete cosine transformation coefficients;maximum-likelihood estimator;primary quality factor;steganography;support vector machine classifiers;Double-compression;JPEG;forensics;steganography;stegenanalysis}
}

@Article{bianchi2012image,
  Title                    = {Image forgery localization via block-grained analysis of JPEG artifacts},
  Author                   = {Bianchi, Tiziano and Piva, Alessandro},
  Journal                  = {IEEE Transactions on Information Forensics and Security (TIFS)},
  Pages                    = {1003-1017},
  Volume                   = {7},
  Year                     = {2012},

  __markedentry            = {[bestagini:1]}
}

@INPROCEEDINGS{Costanzo2010, 
author={M. Barni and A. Costanzo and L. Sabatini}, 
booktitle={IEEE International Symposium on Circuits and Systems (ISCAS)}, 
title={Identification of cut \& paste tampering by means of double-{JPEG} detection and image segmentation}, 
year={2010}, 
keywords={data compression;image coding;image segmentation;object detection;aligned compression grids;cut & paste tampering identification;desynchronized grids;double JPEG compressed images;double-JPEG detection;image segmentation;Colored noise;Forensics;Image analysis;Image coding;Image segmentation;Interpolation;Q factor;Statistical analysis;Statistics;Transform coding}, 
}

@ARTICLE{DeNatale2017, 
author={De Natale, Francesco and Boato, Giulia}, 
journal={IEEE Transactions on Information Forensics and Security (TIFS)}, 
title={Detecting Morphological Filtering of Binary Images}, 
year={2017}, 
volume={12}, 
pages={1207-1217}, 
keywords={document image processing;filtering theory;mathematical analysis;binary image documents;binary image processing;binary images;detecting morphological filtering;mathematical properties;morphologic operators;morphological filters;morphological operators;scanned documents;Detectors;Image forensics;Image processing;Morphology;Printing;Shape;Image forensics;filtering detection;mathematical morphology}, 
}

@ARTICLE{Bahrami2015, 
author={K. Bahrami and A. C. Kot and L. Li and H. Li}, 
journal={IEEE Transactions on Information Forensics and Security (TIFS)}, 
title={Blurred Image Splicing Localization by Exposing Blur Type Inconsistency}, 
year={2015}, 
volume={10}, 
pages={999-1009}, 
keywords={feature extraction;image classification;image forensics;image motion analysis;image restoration;object detection;antiforensics;block-based image partitioning;blur type detection feature extraction;blurred image splicing localization;image block classification;invariant blur type region generation;local blur kernel estimation;motion blur;out-of-focus blur;partial blur type inconsistency exposure;postprocessing operations;spliced region boundary blurring;splicing trace anomaly removal;tampered image resizing;Cameras;Educational institutions;Feature extraction;Image edge detection;Kernel;Noise;Splicing;Blurred image splicing localization;partial blur type;tampering detection}, 
}

@ARTICLE{Pasquini2017, 
author={C. Pasquini and G. Boato and F. P{\'e}rez-Gonz{\'a}lez}, 
journal={IEEE Transactions on Information Forensics and Security (TIFS)}, 
title={Statistical Detection of {JPEG} Traces in Digital Images in Uncompressed Formats}, 
year={2017}, 
volume={12}, 
pages={2890-2905}, 
keywords={Gaussian distribution;discrete cosine transforms;image coding;Benford-Fourier coefficients;DCT coefficients;JPEG compression traces;digital images;discrete cosine transform;generalized Gaussian distribution;image forensics;natural uncompressed images;statistical analysis;statistical detection;Detectors;Digital images;Discrete cosine transforms;Forensics;Image coding;Quantization (signal);Transform coding;Benford’s law;Benford-Fourier coefficients;JPEG compression;image forensics}, 
}

@ARTICLE{Huang2010, 
author={F. Huang and J. Huang and Y. Q. Shi}, 
journal={IEEE Transactions on Information Forensics and Security (TIFS)}, 
title={Detecting Double {JPEG} Compression With the Same Quantization Matrix}, 
year={2010}, 
volume={5}, 
pages={848-856}, 
keywords={computer forensics;data compression;discrete cosine transforms;image coding;matrix algebra;vector quantisation;JPEG image;digital forensics;double JPEG compression;joint photographic expert group;quantization matrix;quantized discrete cosine transform;random perturbation strategy;Decoding;Discrete cosine transforms;Image coding;Image reconstruction;Quantization;Transform coding;Digital forensic;double joint photographic experts group (JPEG) compression;quantization matrix}, 
}

@Comment{jabref-meta: databaseType:bibtex;}
