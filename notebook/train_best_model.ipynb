{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.utils\n",
    "import pickle\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.utils\n",
    "import os\n",
    "import pandas as pd\n",
    "base_path = '/Users/Clara/Desktop/Dottorato/AudioForensics/projects/speech_forensics'\n",
    "\n",
    "\n",
    "def df_to_feat_idx(feat_df, key, fun):\n",
    "    X = feat_df.apply(lambda x: np.asarray(x[key]).squeeze().T[np.where(x['rms_idx'] == 1)].T, axis=1)\n",
    "    X = X.apply(fun)\n",
    "    X = X.apply(lambda x: np.reshape(x, (1, -1)))\n",
    "    X = np.concatenate(X).squeeze()\n",
    "    if len(X.shape) == 1:\n",
    "        X.shape += (1,)\n",
    "    return X\n",
    "\n",
    "\n",
    "def train_one_configuration(norm, filter_outliers, rms_th, alg, win_min_max, num_classes):\n",
    "\n",
    "    # Load the features\n",
    "    test_data_path = base_path + '/notebook/pickle/sphinx/features_test-clean.pkl'\n",
    "    train_data_path = base_path + '/notebook/pickle/sphinx/features_train-clean-100.pkl'\n",
    "    dev_data_path = base_path + '/notebook/pickle/sphinx/features_dev-clean.pkl'\n",
    "\n",
    "    feat_train_df = pd.read_pickle(train_data_path)\n",
    "    feat_train_df['dataset'] = 'train'\n",
    "    feat_test_df = pd.read_pickle(test_data_path)\n",
    "    feat_test_df['dataset'] = 'test'\n",
    "    feat_dev_df = pd.read_pickle(dev_data_path)\n",
    "    feat_dev_df['dataset'] = 'dev'\n",
    "    feat_df = pd.concat([feat_train_df, feat_test_df, feat_dev_df], ignore_index=True)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    feat_df = sklearn.utils.shuffle(feat_df, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    # Apply rms threshold\n",
    "    feat_df['rms_idx'] = feat_df['rms'].apply(lambda x: x >= rms_th * (x.max() - x.min()) + x.min())\n",
    "    feat_df['n_win'] = feat_df['rms'].apply(lambda x: len(x))\n",
    "\n",
    "    # Apply threshold on window number\n",
    "    if win_min_max:\n",
    "        n_win_min = 50\n",
    "        n_win_max = 250\n",
    "        feat_df = feat_df.loc[\n",
    "            np.where(np.logical_and(feat_df['n_win'] >= n_win_min, feat_df['n_win'] <= n_win_max))[0]].reset_index()\n",
    "\n",
    "    # Filter out outliers\n",
    "    if filter_outliers:\n",
    "        idx_0 = (feat_df['y_value'] >= 0) & (feat_df['y_value'] < 0.35) & (feat_df['snr'] == 0)\n",
    "        idx_2 = (feat_df['y_value'] >= 0) & (feat_df['y_value'] < 0.4) & (feat_df['snr'] == 2)\n",
    "        idx_5 = (feat_df['y_value'] >= 0.1) & (feat_df['y_value'] < 0.5) & (feat_df['snr'] == 5)\n",
    "        idx_7 = (feat_df['y_value'] >= 0.1) & (feat_df['y_value'] < 0.7) & (feat_df['snr'] == 7)\n",
    "        idx_10 = (feat_df['y_value'] >= 0.25) & (feat_df['y_value'] < 0.7) & (feat_df['snr'] == 10)\n",
    "        idx_12 = (feat_df['y_value'] >= 0.35) & (feat_df['y_value'] < 1.1) & (feat_df['snr'] == 12)\n",
    "        idx_15 = (feat_df['y_value'] >= 0.4) & (feat_df['y_value'] < 1.1) & (feat_df['snr'] == 15)\n",
    "\n",
    "        idx = idx_0 | idx_2 | idx_5 | idx_7 | idx_10 | idx_12 | idx_15\n",
    "\n",
    "        feat_df = feat_df.loc[np.where(idx == 1)].reset_index()\n",
    "\n",
    "    # Compute feature matrix\n",
    "    key_list = ['mfcc', 'sfl', 'sc', 'sroff', 'zcr', 'rms']\n",
    "    print('Compute features')\n",
    "    X_mean_list = []\n",
    "    for key in key_list:\n",
    "        X_mean_list += [df_to_feat_idx(feat_df, key, lambda x: np.mean(x, axis=-1))]\n",
    "    X_mean = np.concatenate(X_mean_list, axis=1)\n",
    "\n",
    "    X_std_list = []\n",
    "    for key in key_list:\n",
    "        X_std_list += [df_to_feat_idx(feat_df, key, lambda x: np.std(x, axis=-1))]\n",
    "    X_std = np.concatenate(X_std_list, axis=1)\n",
    "\n",
    "    X_max_list = []\n",
    "    for key in key_list:\n",
    "        X_max_list += [df_to_feat_idx(feat_df, key, lambda x: np.max(x, axis=-1))]\n",
    "    X_max = np.concatenate(X_max_list, axis=1)\n",
    "\n",
    "    X_min_list = []\n",
    "    for key in key_list:\n",
    "        X_min_list += [df_to_feat_idx(feat_df, key, lambda x: np.min(x, axis=-1))]\n",
    "    X_min = np.concatenate(X_min_list, axis=1)\n",
    "\n",
    "    X = np.concatenate([X_mean, X_std, X_max, X_min], axis=1)\n",
    "\n",
    "    # Retrieve labels\n",
    "    #y_cl_multi = np.array(feat_df['y_label'], dtype=np.float) - 1  # labels for classification\n",
    "    y_cl = np.array(feat_df['y_value'], dtype=np.float) >= 0.5  # labels for classification\n",
    "    y_rg = np.array(feat_df['y_value'], dtype=np.float)  # Â values for regression\n",
    "\n",
    "    bins = np.arange(0, 1, 1/num_classes)\n",
    "    y_cl_multi = np.array(np.digitize(y_rg, bins) - 1, dtype=np.float)\n",
    "\n",
    "\n",
    "    # Normalize features\n",
    "    if norm == 'zscore':\n",
    "        X_norm = (X - X.mean(axis=0)) / X.std(axis=0)  # z-score\n",
    "    elif norm == 'minmax':\n",
    "        X_norm = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))  # [0, 1]\n",
    "    else:\n",
    "        X_norm = X\n",
    "\n",
    "    # Remove nan and inf\n",
    "    X_norm[np.where(np.isnan(X_norm))] = 0\n",
    "    X_norm[np.where(np.isinf(X_norm))] = 0\n",
    "\n",
    "    # Select algorithm\n",
    "    if alg == 'svm':\n",
    "        clf = sklearn.svm.SVC(kernel='rbf', gamma='auto', random_state=0)\n",
    "        clf_bin = sklearn.svm.SVC(kernel='rbf', gamma='auto', random_state=0)\n",
    "        regr = sklearn.svm.SVR(gamma='auto')\n",
    "    else:\n",
    "        clf = sklearn.ensemble.RandomForestClassifier(class_weight='balanced', random_state=0)\n",
    "        clf_bin = sklearn.svm.SVC(kernel='rbf', gamma='auto', random_state=0)\n",
    "        regr = sklearn.ensemble.RandomForestRegressor(random_state=0)\n",
    "\n",
    "    # Train\n",
    "    print('fit')\n",
    "    #cl = clf_bin.fit(X_norm, y_cl)\n",
    "    mcl = clf.fit(X_norm, y_cl_multi)\n",
    "    #r = regr.fit(X_norm, y_rg)\n",
    "\n",
    "    #out_filename = base_path + '/models/rai_r.pkl'\n",
    "    #with open(out_filename, 'wb') as file:\n",
    "    #    pickle.dump(r, file)\n",
    "\n",
    "    #out_filename = base_path + '/models/rai_cl.pkl'\n",
    "    #with open(out_filename, 'wb') as file:\n",
    "    #    pickle.dump(cl, file)\n",
    "\n",
    "    out_filename = base_path + '/models/rai_mcl.pkl'\n",
    "    with open(out_filename, 'wb') as file:\n",
    "        pickle.dump(mcl, file)\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute features\n",
      "fit\n"
     ]
    }
   ],
   "source": [
    "norm = 'zscore'\n",
    "filter_outliers = True\n",
    "win_min_max = True\n",
    "rms_th = 0\n",
    "alg = 'svm'\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "train_one_configuration(norm, filter_outliers, rms_th, alg, win_min_max, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'zscore'\n",
    "filter_outliers = True\n",
    "win_min_max = True\n",
    "rms_th = 0\n",
    "alg = 'svm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_configuration(norm, filter_outliers, rms_th, alg, win_min_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
