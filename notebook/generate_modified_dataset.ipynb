{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa \n",
    "import librosa.core\n",
    "import librosa.util\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(in_path, dataset_name, noise_type, snr):\n",
    "    \n",
    "    # generate output file path\n",
    "    dest_path = in_path.replace(dataset_name, '{:s}_{:s}_{:d}'.format(dataset_name, noise_type, snr))    \n",
    "    dest_path = dest_path.replace(dest_path.split('.')[-1], 'wav')\n",
    "\n",
    "    # check if file exists\n",
    "    if os.path.exists(dest_path):\n",
    "        return\n",
    "\n",
    "    # read clean signal\n",
    "    clean, samplerate = sf.read(in_path)\n",
    "    clean = np.array(clean)\n",
    "    \n",
    "    # read and normalize noise\n",
    "    noise_path = os.path.join('/nas/home/cborrelli/speech_forensics/dataset/noise', noise_type + '.wav')\n",
    "    noise_samplerate, noise = scipy.io.wavfile.read(noise_path)\n",
    "    noise = np.float32(noise) / np.float32(2**(16-1))\n",
    "    \n",
    "    # resample if necessary\n",
    "    if (samplerate < noise_samplerate):\n",
    "        noise = librosa.resample(noise, noise_samplerate, samplerate)\n",
    "    else:\n",
    "        raise Exception('Noise sampling rate is too low.') \n",
    "    \n",
    "    # trim the noise\n",
    "    if (noise.shape[0] > clean.shape[0]):\n",
    "        noise = noise[:clean.shape[0]]\n",
    "    else:\n",
    "        raise Exception('Noise is too short.') \n",
    "\n",
    "    # normalize to 0 dB nominal level\n",
    "    norm_factor = np.sqrt(np.mean(np.abs(clean)**2) / np.mean(np.abs(noise)**2))\n",
    "    noise = noise * norm_factor\n",
    "    \n",
    "    # apply scaling\n",
    "    noise_gain = 1 / (10**(snr/20))\n",
    "    noise_scaled = noise*noise_gain\n",
    "    \n",
    "    # mix the two signals\n",
    "    noisy = 0.5*(clean + noise_scaled)\n",
    "    \n",
    "    # save file to disk\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(dest_path))\n",
    "    except:\n",
    "        pass\n",
    "    sp.io.wavfile.write(dest_path, samplerate, noisy)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_dataset(dataset_csv_path, noise_type, snr):\n",
    "    orig_db = pd.read_csv(dataset_csv_path)\n",
    "    in_path_list = orig_db['path'].to_list()\n",
    "    dataset_name = orig_db['librispeech_folder'].unique()[0]\n",
    "\n",
    "    f_part = partial(add_noise, dataset_name=dataset_name, noise_type=noise_type, snr=snr)\n",
    "\n",
    "    pool = Pool(cpu_count())\n",
    "\n",
    "    for _ in tqdm.tqdm(pool.imap_unordered(f_part, in_path_list), total=len(in_path_list)):\n",
    "        pass\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = ['dev-clean']\n",
    "\n",
    "#in_dataset_csv = '../csv/dev-clean.csv'\n",
    "noise_type = ['train']\n",
    "snr = [0, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in dataset_name:\n",
    "    in_dataset_csv = '../csv/' + a +'.csv'\n",
    "    for n in noise_type:\n",
    "        for s in snr:\n",
    "            add_noise_dataset(in_dataset_csv, n, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
