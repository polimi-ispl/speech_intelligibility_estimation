{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa \n",
    "import librosa.core\n",
    "import librosa.util\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve path to files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path = \"dataset/noise/\"\n",
    "noise_files = [f for f in os.listdir(noise_path)]\n",
    "\n",
    "# here we will have the list of the files that have a quite accurate transcription\n",
    "\n",
    "orig_db = pd.read_csv('csv/orig_librispeech_dev-clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_db['librispeech_folder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for storing dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['orig_name', 'orig_path', 'name', 'path', 'noise_type', 'SNR', 'talker', 'book','orig_transcription', 'orig_transcription_path']\n",
    "db_info = pd.DataFrame(columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters (eventually fix and remove constraint)\n",
    "\n",
    "## noise files are wav 16 at 48000\n",
    "nbit = 16\n",
    "SNR = [0,5,10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization of the folder dataset\n",
    "1. speech : noisy files \n",
    "    * file directory: one folder for each file of the LibriSpeech dataset; *example dir name*: <b>84-121550-0000</b>\n",
    "        - noise type: one folder for each type of noise; *example dir name*: <b>train</b> <br> \n",
    "          here noisy speech files with different SNRs; *example file path*: <b>84-121550-0000/train/84-121550-0000_train_5.wav</b>\n",
    "          \n",
    "2. noise : noise files\n",
    "3. orig : original files\n",
    "4. trans : original transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add noise to clean files\n",
    "Maybe we can avoid to have 3 nested for cycles?<br>\n",
    "Probably can be useful to have a pipeline made of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here in future we should read from a pandas dataframe having the paths for all the files we use from LibriSpeech\n",
    "\n",
    "orig_librispeech_subset_path = ['/nas/public/dataset/LibriSpeech/dev-clean']\n",
    "orig_librispeech_subset = ['dev-clean']\n",
    "\n",
    "which_subset_compute = 0\n",
    "\n",
    "orig_db_subset = orig_db[(orig_db['librispeech_folder'] == orig_librispeech_subset_path[which_subset_compute])]\n",
    "\n",
    "\n",
    "\n",
    "for index,row in orig_db_subset.iterrows():\n",
    "    \n",
    "    origfile_path = row['path']\n",
    "    clean, orig_samplerate = sf.read(origfile_path)\n",
    "    clean = np.array(clean)\n",
    "    \n",
    "    transcription_path = row['transcription_path']\n",
    "    with open(transcription_path) as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    for row in content:\n",
    "        splitted = row.split(' ')\n",
    "        if splitted[0] == origfile_name:\n",
    "            transcription = ' '.join(splitted[1:])\n",
    "            break\n",
    "    \n",
    "    for n in noise_files:\n",
    "        noise_name = n.replace('.wav','')\n",
    "        noise_samplerate, noise = scipy.io.wavfile.read(os.path.join(noise_path, n))\n",
    "        noise = np.float32(noise)/ np.float32(2**(nbit-1))\n",
    "\n",
    "        if(orig_samplerate > noise_samplerate):\n",
    "            clean = librosa.resample(clean, orig_samplerate, noise_samplerate)\n",
    "            samplerate = noise_samplerate\n",
    "        else:\n",
    "            noise = librosa.resample(noise, noise_samplerate, orig_samplerate)\n",
    "            samplerate = orig_samplerate\n",
    "            \n",
    "        if (noise.shape[0] > clean.shape[0]):\n",
    "            noise = noise[:clean.shape[0]]\n",
    "        \n",
    "        \n",
    "        norm_factor = np.sqrt(np.mean(np.abs(clean)**2)/np.mean(np.abs(noise)**2))\n",
    "        noise = noise*norm_factor\n",
    "        \n",
    "        \n",
    "        for s in SNR:\n",
    "            noise_gain = 1/(10**(s/20))\n",
    "            noise_scaled = noise*noise_gain\n",
    "            noisy = clean + noise_scaled\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(orig_librispeech_subset+'_'+noise_name):\n",
    "                    os.makedirs(directory)\n",
    "        \n",
    "    if(index==10):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('/nas/public/dataset/LibriSpeech/dev-clean/2277/149896/2277-149896-0015.flac') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick some random file and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file = db_info.sample(n=1)\n",
    "noise_samplerate, noise = scipy.io.wavfile.read(random_file['path'].values[0])\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(noise, rate=noise_samplerate) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
